{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01141089",
   "metadata": {},
   "source": [
    "# Assignment 4 - Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635d16d5",
   "metadata": {},
   "source": [
    "To get \n",
    "information about selenium Exceptions. You may visit following links:\n",
    "1. https://selenium-python.readthedocs.io/api.html\n",
    "2. https://www.guru99.com/exception-handling-selenium.html\n",
    "3. https://stackoverflow.com/questions/38022658/selenium-python-handling-no-such-element\u0002exception/38023345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "376243bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Import Selenium webdriver\n",
    "from selenium import webdriver\n",
    "\n",
    "# Import required exceptions which need to be handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementNotInteractableException, ElementClickInterceptedException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# Import requests\n",
    "import requests\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "import urllib.request\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd83839",
   "metadata": {},
   "source": [
    "### 1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc3cd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\JPGD\\Documents\\ANDREA GOMEZ\\FLIP ROBO TECHNOLOGIES INTERNSHIP\\chromedriver_win32 2\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6898211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the page on automated chrome browser\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a4d104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_body=driver.find_element(By.XPATH,'//*[@id=\"mw-content-text\"]/div[1]/table[2]')\n",
    "Data_1=[]\n",
    "for tr in table_body.find_elements(By.XPATH,\"//tr\"):\n",
    "    row=[item.text for item in tr.find_elements(By.XPATH,'.//td')]\n",
    "    Data_1.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6d20ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "632bdebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists\n",
    "rank1=[]\n",
    "nm=[]\n",
    "art=[]\n",
    "upd=[]\n",
    "views1=[]\n",
    "\n",
    "# Scraping search details\n",
    "Rank_tag=driver.find_elements(By.XPATH,'//*[@id=\"mw-content-text\"]/div[1]/table[2]/tbody/tr/td[1]')\n",
    "Name_tag=driver.find_elements(By.XPATH,'/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[2]/tbody/tr/td[2]')\n",
    "Artist_tag=driver.find_elements(By.XPATH,'//*[@id=\"mw-content-text\"]/div[1]/table[2]/tbody/tr/td[3]')\n",
    "Upload_date=driver.find_elements(By.XPATH,'//*[@id=\"mw-content-text\"]/div[1]/table[2]/tbody/tr/td[5]')\n",
    "Views=driver.find_elements(By.XPATH,'//*[@id=\"mw-content-text\"]/div[1]/table[2]/tbody/tr/td[4]')\n",
    "\n",
    "for rank in Rank_tag:\n",
    "    rank1.append(rank.text)\n",
    "for name in Name_tag:\n",
    "    nm.append(name.text.split(\"[\"))\n",
    "for artist in Artist_tag:\n",
    "    art.append(artist.text)\n",
    "for upload in Upload_date:\n",
    "    upd.append(upload.text)\n",
    "for views in Views:\n",
    "    views1.append(views.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "775f43bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Baby Shark Dance', 'Despacito', 'Johny Johny Yes Papa', 'Bath Song', 'Shape of You', 'See You Again', 'Phonics Song with Two Words', 'Wheels on the Bus', 'Uptown Funk', 'Learning Colors – Colorful Eggs on a Farm', 'Gangnam Style', 'Masha and the Bear – Recipe for Disaster', 'Dame Tu Cosita', 'Axel F', 'Sugar', 'Roar', 'Counting Stars', 'Sorry', 'Baa Baa Black Sheep', 'Thinking Out Loud', 'Waka Waka (This Time for Africa)', 'Dark Horse', 'Lakdi Ki Kathi', 'Faded', 'Perfect', 'Let Her Go', 'Girls Like You', 'Humpty the train on a fruits ride', 'Lean On', 'Bailando']\n"
     ]
    }
   ],
   "source": [
    "nm2=[]\n",
    "name1=[x[0] for x in nm]\n",
    "for i in name1:\n",
    "    nm2.append(i.replace('\"',\"\"))\n",
    "    \n",
    "#print(nm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7178633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(rank1),len(nm2),len(art),len(upd),len(views1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "805bca22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ranking</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.</th>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.</th>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.</th>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.</th>\n",
       "      <td>Bath Song</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.</th>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.</th>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.</th>\n",
       "      <td>Phonics Song with Two Words</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.</th>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.</th>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.</th>\n",
       "      <td>Learning Colors – Colorful Eggs on a Farm</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.</th>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.</th>\n",
       "      <td>Masha and the Bear – Recipe for Disaster</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.</th>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.</th>\n",
       "      <td>Axel F</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.</th>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.</th>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.</th>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.</th>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.</th>\n",
       "      <td>Baa Baa Black Sheep</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.</th>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.</th>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.</th>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.</th>\n",
       "      <td>Lakdi Ki Kathi</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.</th>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.</th>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.</th>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.</th>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.</th>\n",
       "      <td>Humpty the train on a fruits ride</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.</th>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.</th>\n",
       "      <td>Bailando</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Name  \\\n",
       "Ranking                                              \n",
       "1.                                Baby Shark Dance   \n",
       "2.                                       Despacito   \n",
       "3.                            Johny Johny Yes Papa   \n",
       "4.                                       Bath Song   \n",
       "5.                                    Shape of You   \n",
       "6.                                   See You Again   \n",
       "7.                     Phonics Song with Two Words   \n",
       "8.                               Wheels on the Bus   \n",
       "9.                                     Uptown Funk   \n",
       "10.      Learning Colors – Colorful Eggs on a Farm   \n",
       "11.                                  Gangnam Style   \n",
       "12.       Masha and the Bear – Recipe for Disaster   \n",
       "13.                                 Dame Tu Cosita   \n",
       "14.                                         Axel F   \n",
       "15.                                          Sugar   \n",
       "16.                                           Roar   \n",
       "17.                                 Counting Stars   \n",
       "18.                                          Sorry   \n",
       "19.                            Baa Baa Black Sheep   \n",
       "20.                              Thinking Out Loud   \n",
       "21.               Waka Waka (This Time for Africa)   \n",
       "22.                                     Dark Horse   \n",
       "23.                                 Lakdi Ki Kathi   \n",
       "24.                                          Faded   \n",
       "25.                                        Perfect   \n",
       "26.                                     Let Her Go   \n",
       "27.                                 Girls Like You   \n",
       "28.              Humpty the train on a fruits ride   \n",
       "29.                                        Lean On   \n",
       "30.                                       Bailando   \n",
       "\n",
       "                                                Artist        Upload Date  \\\n",
       "Ranking                                                                     \n",
       "1.         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "2.                                          Luis Fonsi   January 12, 2017   \n",
       "3.                                         LooLoo Kids    October 8, 2016   \n",
       "4.                          Cocomelon – Nursery Rhymes        May 2, 2018   \n",
       "5.                                          Ed Sheeran   January 30, 2017   \n",
       "6.                                         Wiz Khalifa      April 6, 2015   \n",
       "7.                                           ChuChu TV      March 6, 2014   \n",
       "8.                          Cocomelon – Nursery Rhymes       May 24, 2018   \n",
       "9.                                         Mark Ronson  November 19, 2014   \n",
       "10.                                        Miroshka TV  February 27, 2018   \n",
       "11.                                                Psy      July 15, 2012   \n",
       "12.                                         Get Movies   January 31, 2012   \n",
       "13.                                          El Chombo      April 5, 2018   \n",
       "14.                                         Crazy Frog      June 16, 2009   \n",
       "15.                                           Maroon 5   January 14, 2015   \n",
       "16.                                         Katy Perry  September 5, 2013   \n",
       "17.                                        OneRepublic       May 31, 2013   \n",
       "18.                                      Justin Bieber   October 22, 2015   \n",
       "19.                         Cocomelon – Nursery Rhymes      June 25, 2018   \n",
       "20.                                         Ed Sheeran    October 7, 2014   \n",
       "21.                                            Shakira       June 4, 2010   \n",
       "22.                                         Katy Perry  February 20, 2014   \n",
       "23.                                       Jingle Toons      June 14, 2018   \n",
       "24.                                        Alan Walker   December 3, 2015   \n",
       "25.                                         Ed Sheeran   November 9, 2017   \n",
       "26.                                          Passenger      July 25, 2012   \n",
       "27.                                           Maroon 5       May 31, 2018   \n",
       "28.      Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "29.                                        Major Lazer     March 22, 2015   \n",
       "30.                                   Enrique Iglesias     April 11, 2014   \n",
       "\n",
       "         Views  \n",
       "Ranking         \n",
       "1.       12.85  \n",
       "2.        8.16  \n",
       "3.        6.70  \n",
       "4.        6.20  \n",
       "5.        6.00  \n",
       "6.        5.89  \n",
       "7.        5.30  \n",
       "8.        5.24  \n",
       "9.        4.92  \n",
       "10.       4.89  \n",
       "11.       4.80  \n",
       "12.       4.55  \n",
       "13.       4.35  \n",
       "14.       3.91  \n",
       "15.       3.87  \n",
       "16.       3.80  \n",
       "17.       3.79  \n",
       "18.       3.66  \n",
       "19.       3.64  \n",
       "20.       3.60  \n",
       "21.       3.59  \n",
       "22.       3.52  \n",
       "23.       3.48  \n",
       "24.       3.45  \n",
       "25.       3.45  \n",
       "26.       3.44  \n",
       "27.       3.42  \n",
       "28.       3.41  \n",
       "29.       3.38  \n",
       "30.       3.38  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.DataFrame({'Ranking':rank1,'Name':nm2,'Artist':art,'Upload Date':upd,'Views':views1})\n",
    "df1.set_index('Ranking',inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51340354",
   "metadata": {},
   "source": [
    "### 2. Scrape the details team India’s international fixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1stODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea9d2591",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\JPGD\\Documents\\ANDREA GOMEZ\\FLIP ROBO TECHNOLOGIES INTERNSHIP\\chromedriver_win32 2\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e75b5004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the page on automated chrome browser\n",
    "driver.get(\"https://www.bcci.tv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "133cb4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close popup window\n",
    "closew=driver.find_element(By.XPATH,\"/html/body/div[15]/button\")\n",
    "closew.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1587669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click \"International\" option\n",
    "search_button=driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d81a5537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create empty lists\n",
    "m_title=[]\n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "time=[]\n",
    "\n",
    "\n",
    "# Scraping search details\n",
    "t_tag=driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "series_tag=driver.find_elements('tag name','h5')\n",
    "place_tag=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]')\n",
    "date_tag=driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "time_tag=driver.find_elements(By.CLASS_NAME,'match-info')\n",
    "\n",
    "for i in t_tag:\n",
    "    m_title.append(i.text.replace(\" -\",\"\"))\n",
    "for i in series_tag:\n",
    "    series.append(i.text)\n",
    "for i in place_tag:\n",
    "    place.append(i.text)\n",
    "for i in date_tag:\n",
    "    date.append(i.text)\n",
    "for i in time_tag:\n",
    "    time.append(i.text.split(\"\\n\"))\n",
    "time=[x[1] for x in time]\n",
    "series.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a3837ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 8 8 8\n"
     ]
    }
   ],
   "source": [
    "print(len(m_title),len(series),len(place),len(date),len(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "00a754eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>9 JUL 2023</td>\n",
       "      <td>3:00 AM HDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>11 JUL 2023</td>\n",
       "      <td>3:00 AM HDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Windsor Park,</td>\n",
       "      <td>12 JUL 2023</td>\n",
       "      <td>9:00 AM HDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>13 JUL 2023</td>\n",
       "      <td>3:00 AM HDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>15 JUL 2023</td>\n",
       "      <td>10:30 PM HDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>18 JUL 2023</td>\n",
       "      <td>10:30 PM HDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Queen's Park Oval,</td>\n",
       "      <td>20 JUL 2023</td>\n",
       "      <td>9:00 AM HDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>21 JUL 2023</td>\n",
       "      <td>10:30 PM HDE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match Title                               Series  \\\n",
       "1    1st T20I  INDIA WOMEN TOUR OF BANGLADESH 2023   \n",
       "2    2nd T20I  INDIA WOMEN TOUR OF BANGLADESH 2023   \n",
       "3    1st Test       INDIA TOUR OF WEST INDIES 2023   \n",
       "4    3rd T20I  INDIA WOMEN TOUR OF BANGLADESH 2023   \n",
       "5     1st ODI  INDIA WOMEN TOUR OF BANGLADESH 2023   \n",
       "6     2nd ODI  INDIA WOMEN TOUR OF BANGLADESH 2023   \n",
       "7    2nd Test       INDIA TOUR OF WEST INDIES 2023   \n",
       "8     3rd ODI  INDIA WOMEN TOUR OF BANGLADESH 2023   \n",
       "\n",
       "                                    Place         Date          Time  \n",
       "1  Shere Bangla National Stadium, Mirpur,   9 JUL 2023   3:00 AM HDE  \n",
       "2  Shere Bangla National Stadium, Mirpur,  11 JUL 2023   3:00 AM HDE  \n",
       "3                           Windsor Park,  12 JUL 2023   9:00 AM HDE  \n",
       "4  Shere Bangla National Stadium, Mirpur,  13 JUL 2023   3:00 AM HDE  \n",
       "5  Shere Bangla National Stadium, Mirpur,  15 JUL 2023  10:30 PM HDE  \n",
       "6  Shere Bangla National Stadium, Mirpur,  18 JUL 2023  10:30 PM HDE  \n",
       "7                      Queen's Park Oval,  20 JUL 2023   9:00 AM HDE  \n",
       "8  Shere Bangla National Stadium, Mirpur,  21 JUL 2023  10:30 PM HDE  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.DataFrame({'Match Title':m_title,'Series':series,'Place':place,'Date':date,'Time':time})\n",
    "df2.index+=1\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28f2451",
   "metadata": {},
   "source": [
    "### 3. Scrape the details of State-wise GDP of India from statisticstime.com. \n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d27799f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\JPGD\\Documents\\ANDREA GOMEZ\\FLIP ROBO TECHNOLOGIES INTERNSHIP\\chromedriver_win32 2\\chromedriver.exe\")\n",
    "\n",
    "# Opening the page on automated chrome browser\n",
    "driver.get(\"http://statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "15cf0b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close popup window\n",
    "closew=driver.find_element(By.XPATH,\"/html/body/div[1]/div/a\")\n",
    "closew.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bed3316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click \"Economy\" page\n",
    "search_button=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button')\n",
    "search_button.click()\n",
    "\n",
    "# Click \"India\" option\n",
    "search_button=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "257a465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click \"GDP of Indian States\" option\n",
    "search_button=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bf341023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists\n",
    "\n",
    "Rank_3=[]\n",
    "State=[]\n",
    "GSDP1_CP=[]\n",
    "GSDP2_CP=[]\n",
    "Share=[]\n",
    "GDP_B=[]\n",
    "\n",
    "rank_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[1]')\n",
    "state_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[2]')\n",
    "gsdp_1_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "gsdp_2_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[3]')\n",
    "share_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "gdp_b_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "\n",
    "for i in rank_tag:\n",
    "    Rank_3.append(i.text)\n",
    "for i in state_tag:\n",
    "    State.append(i.text)\n",
    "for i in gsdp_1_tag:\n",
    "    GSDP1_CP.append(i.text)\n",
    "for i in gsdp_1_tag:\n",
    "    GSDP2_CP.append(i.text)\n",
    "for i in share_tag:\n",
    "    Share.append(i.text)\n",
    "for i in gdp_b_tag:\n",
    "    GDP_B.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "dae77c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 33 33 33 33 33\n"
     ]
    }
   ],
   "source": [
    "print(len(Rank_3),len(State),len(GSDP1_CP),len(GSDP2_CP),len(Share),len(GDP_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8cdd4c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)- at current prices</th>\n",
       "      <th>GSDP(19-20)- at current prices</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          State GSDP(18-19)- at current prices  \\\n",
       "Rank                                                             \n",
       "1                   Maharashtra                      2,632,792   \n",
       "2                    Tamil Nadu                      1,630,208   \n",
       "3                 Uttar Pradesh                      1,584,764   \n",
       "4                       Gujarat                      1,502,899   \n",
       "5                     Karnataka                      1,493,127   \n",
       "6                   West Bengal                      1,089,898   \n",
       "7                     Rajasthan                        942,586   \n",
       "8                Andhra Pradesh                        862,957   \n",
       "9                     Telangana                        861,031   \n",
       "10               Madhya Pradesh                        809,592   \n",
       "11                       Kerala                        781,653   \n",
       "12                        Delhi                        774,870   \n",
       "13                      Haryana                        734,163   \n",
       "14                        Bihar                        530,363   \n",
       "15                       Punjab                        526,376   \n",
       "16                       Odisha                        487,805   \n",
       "17                        Assam                        315,881   \n",
       "18                 Chhattisgarh                        304,063   \n",
       "19                    Jharkhand                        297,204   \n",
       "20                  Uttarakhand                        245,895   \n",
       "21              Jammu & Kashmir                        155,956   \n",
       "22             Himachal Pradesh                        153,845   \n",
       "23                          Goa                         73,170   \n",
       "24                      Tripura                         49,845   \n",
       "25                   Chandigarh                         42,114   \n",
       "26                   Puducherry                         34,433   \n",
       "27                    Meghalaya                         33,481   \n",
       "28                       Sikkim                         28,723   \n",
       "29                      Manipur                         27,870   \n",
       "30                     Nagaland                         27,283   \n",
       "31            Arunachal Pradesh                         24,603   \n",
       "32                      Mizoram                         22,287   \n",
       "33    Andaman & Nicobar Islands                              -   \n",
       "\n",
       "     GSDP(19-20)- at current prices Share(18-19) GDP($ billion)  \n",
       "Rank                                                             \n",
       "1                         2,632,792       13.94%        399.921  \n",
       "2                         1,630,208        8.63%        247.629  \n",
       "3                         1,584,764        8.39%        240.726  \n",
       "4                         1,502,899        7.96%        228.290  \n",
       "5                         1,493,127        7.91%        226.806  \n",
       "6                         1,089,898        5.77%        165.556  \n",
       "7                           942,586        4.99%        143.179  \n",
       "8                           862,957        4.57%        131.083  \n",
       "9                           861,031        4.56%        130.791  \n",
       "10                          809,592        4.29%        122.977  \n",
       "11                          781,653        4.14%        118.733  \n",
       "12                          774,870        4.10%        117.703  \n",
       "13                          734,163        3.89%        111.519  \n",
       "14                          530,363        2.81%         80.562  \n",
       "15                          526,376        2.79%         79.957  \n",
       "16                          487,805        2.58%         74.098  \n",
       "17                          315,881        1.67%         47.982  \n",
       "18                          304,063        1.61%         46.187  \n",
       "19                          297,204        1.57%         45.145  \n",
       "20                          245,895        1.30%         37.351  \n",
       "21                          155,956        0.83%         23.690  \n",
       "22                          153,845        0.81%         23.369  \n",
       "23                           73,170        0.39%         11.115  \n",
       "24                           49,845        0.26%          7.571  \n",
       "25                           42,114        0.22%          6.397  \n",
       "26                           34,433        0.18%          5.230  \n",
       "27                           33,481        0.18%          5.086  \n",
       "28                           28,723        0.15%          4.363  \n",
       "29                           27,870        0.15%          4.233  \n",
       "30                           27,283        0.14%          4.144  \n",
       "31                           24,603        0.13%          3.737  \n",
       "32                           22,287        0.12%          3.385  \n",
       "33                                -            -              -  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.DataFrame({'Rank':Rank_3,'State':State,'GSDP(18-19)- at current prices':GSDP1_CP,'GSDP(19-20)- at current prices':GSDP2_CP,\n",
    "                  'Share(18-19)':Share,'GDP($ billion)':GDP_B})\n",
    "df3.set_index('Rank',inplace=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c719507a",
   "metadata": {},
   "source": [
    "### 4. Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf80855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\JPGD\\Documents\\ANDREA GOMEZ\\FLIP ROBO TECHNOLOGIES INTERNSHIP\\chromedriver_win32 2\\chromedriver.exe\")\n",
    "\n",
    "# Opening the page on automated chrome browser\n",
    "driver.get(\"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5a16c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click the trending button\n",
    "# search_button=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[1]/div[2]/button/span/span/div[3]')\n",
    "# search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b646b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/47343091/python-selenium-scraping-dynamic-drop-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce640b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click open source button\n",
    "search_button=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "search_button.click()\n",
    "\n",
    "# Click the trending button\n",
    "search_button=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc384993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch URL to open each repository link\n",
    "\n",
    "repository_opening_url=[]\n",
    "\n",
    "url=driver.find_elements(By.XPATH,'/html/body/div[1]/div[4]/main/div[3]/div/div[2]/article/h2/a')\n",
    "for i in url:\n",
    "    repository_opening_url.append(i.get_attribute('href'))\n",
    "    repository_opening_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deed8852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    " print(len(repository_opening_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40c139cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists\n",
    "Repository_t=[] \n",
    "Repository_description=[]\n",
    "Contributors_count=[]\n",
    "Language=[]\n",
    "# Scraping data\n",
    "\n",
    "for i in repository_opening_url:\n",
    "    driver.get(i)\n",
    "    time.sleep(10)\n",
    "    try:\n",
    "        R_tag=driver.find_element(By.XPATH,'//strong[@class=\"mr-2 flex-self-stretch\"]')\n",
    "        Repository_t.append(R_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        Repository_t.append(\"-\")\n",
    "    try:\n",
    "        Rd_tag=driver.find_element(By.XPATH,'//p[@class=\"f4 my-3\"]')\n",
    "        Repository_description.append(Rd_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        Repository_description.append(\"-\")\n",
    "    try:\n",
    "        C_count_tag=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/main/turbo-frame/div/div/div/div[2]/div[2]/div/div[4]/div/h2/a/span')\n",
    "        Contributors_count.append(C_count_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        Contributors_count.append(\"-\")\n",
    "    try:\n",
    "        L_tag=driver.find_element(By.XPATH,'//span[@class=\"color-fg-default text-bold mr-1\"]')\n",
    "        Language.append(L_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        Language.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5101af40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(Repository_t),len(Repository_description),len(Contributors_count),len(Language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a944c212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MobileSAM</td>\n",
       "      <td>This is the official code for Faster Segment A...</td>\n",
       "      <td>4</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mpt-30B-inference</td>\n",
       "      <td>Run inference on MPT-30B using CPU</td>\n",
       "      <td>-</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Block-Pornographic-Replies</td>\n",
       "      <td>屏蔽推特回复下的黄推。Block pornographic replies below th...</td>\n",
       "      <td>-</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>open-source-course</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PowerShell</td>\n",
       "      <td>PowerShell for every system!</td>\n",
       "      <td>-</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DragGAN</td>\n",
       "      <td>Official Code for DragGAN (SIGGRAPH 2023)</td>\n",
       "      <td>14</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>folly</td>\n",
       "      <td>An open-source C++ library developed and used ...</td>\n",
       "      <td>-</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tkinter-Designer</td>\n",
       "      <td>An easy and fast way to create a Python GUI 🐍</td>\n",
       "      <td>82</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>papers-we-love</td>\n",
       "      <td>Papers from the computer science community to ...</td>\n",
       "      <td>-</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LLMs-In-China</td>\n",
       "      <td>中国大模型</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>project-based-learning</td>\n",
       "      <td>Curated list of project-based tutorials</td>\n",
       "      <td>104</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>copilot-analysis</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>eShopOnContainers</td>\n",
       "      <td>Cross-platform .NET sample microservices and c...</td>\n",
       "      <td>12</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>free-programming-books</td>\n",
       "      <td>📚 Freely available programming books</td>\n",
       "      <td>2,517</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>chinese-poetry</td>\n",
       "      <td>The most comprehensive database of Chinese poe...</td>\n",
       "      <td></td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>telegram-groups</td>\n",
       "      <td>经过精心筛选，从5000+个电报群组/频道/机器人中挑选出的优质推荐！如果您有更多值得推荐的...</td>\n",
       "      <td>-</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>questdb</td>\n",
       "      <td>An open source time-series database for fast i...</td>\n",
       "      <td>114</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>unidbg-fetch-qsign</td>\n",
       "      <td>获取QQSign通过Unidbg</td>\n",
       "      <td>-</td>\n",
       "      <td>Kotlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>composer</td>\n",
       "      <td>Train neural networks up to 7x faster</td>\n",
       "      <td>77</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DataX</td>\n",
       "      <td>DataX是阿里云DataWorks数据集成的开源版本。</td>\n",
       "      <td>-</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AFFiNE</td>\n",
       "      <td>There can be more than Notion and Miro. AFFiNE...</td>\n",
       "      <td>9</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>aigc</td>\n",
       "      <td>《构筑大语言模型应用：应用开发与架构设计》一本关于 LLM 在真实世界应用的开源电子书，介绍...</td>\n",
       "      <td>6</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>background-removal-js</td>\n",
       "      <td>Remove backgrounds from images directly in the...</td>\n",
       "      <td>1</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sourcegraph</td>\n",
       "      <td>Code Intelligence Platform</td>\n",
       "      <td>347</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>vue3-antd-admin</td>\n",
       "      <td>基于vue-cli5.x/vite2.x + vue3.x + ant-design-vue...</td>\n",
       "      <td>7</td>\n",
       "      <td>Vue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Repository Title  \\\n",
       "1                    MobileSAM   \n",
       "2            mpt-30B-inference   \n",
       "3   Block-Pornographic-Replies   \n",
       "4           open-source-course   \n",
       "5                   PowerShell   \n",
       "6                      DragGAN   \n",
       "7                        folly   \n",
       "8             Tkinter-Designer   \n",
       "9               papers-we-love   \n",
       "10               LLMs-In-China   \n",
       "11      project-based-learning   \n",
       "12            copilot-analysis   \n",
       "13           eShopOnContainers   \n",
       "14      free-programming-books   \n",
       "15              chinese-poetry   \n",
       "16             telegram-groups   \n",
       "17                     questdb   \n",
       "18          unidbg-fetch-qsign   \n",
       "19                    composer   \n",
       "20                       DataX   \n",
       "21                      AFFiNE   \n",
       "22                        aigc   \n",
       "23       background-removal-js   \n",
       "24                 sourcegraph   \n",
       "25             vue3-antd-admin   \n",
       "\n",
       "                               Repository Description Contributors Count  \\\n",
       "1   This is the official code for Faster Segment A...                  4   \n",
       "2                  Run inference on MPT-30B using CPU                  -   \n",
       "3   屏蔽推特回复下的黄推。Block pornographic replies below th...                  -   \n",
       "4                                                   -                  -   \n",
       "5                        PowerShell for every system!                  -   \n",
       "6           Official Code for DragGAN (SIGGRAPH 2023)                 14   \n",
       "7   An open-source C++ library developed and used ...                  -   \n",
       "8       An easy and fast way to create a Python GUI 🐍                 82   \n",
       "9   Papers from the computer science community to ...                  -   \n",
       "10                                              中国大模型                  -   \n",
       "11            Curated list of project-based tutorials                104   \n",
       "12                                                  -                  -   \n",
       "13  Cross-platform .NET sample microservices and c...                 12   \n",
       "14               📚 Freely available programming books              2,517   \n",
       "15  The most comprehensive database of Chinese poe...                      \n",
       "16  经过精心筛选，从5000+个电报群组/频道/机器人中挑选出的优质推荐！如果您有更多值得推荐的...                  -   \n",
       "17  An open source time-series database for fast i...                114   \n",
       "18                                   获取QQSign通过Unidbg                  -   \n",
       "19              Train neural networks up to 7x faster                 77   \n",
       "20                       DataX是阿里云DataWorks数据集成的开源版本。                  -   \n",
       "21  There can be more than Notion and Miro. AFFiNE...                  9   \n",
       "22  《构筑大语言模型应用：应用开发与架构设计》一本关于 LLM 在真实世界应用的开源电子书，介绍...                  6   \n",
       "23  Remove backgrounds from images directly in the...                  1   \n",
       "24                         Code Intelligence Platform                347   \n",
       "25  基于vue-cli5.x/vite2.x + vue3.x + ant-design-vue...                  7   \n",
       "\n",
       "            Language  \n",
       "1   Jupyter Notebook  \n",
       "2             Python  \n",
       "3         JavaScript  \n",
       "4                  -  \n",
       "5                 C#  \n",
       "6             Python  \n",
       "7                C++  \n",
       "8             Python  \n",
       "9              Shell  \n",
       "10                 -  \n",
       "11                 -  \n",
       "12        JavaScript  \n",
       "13                C#  \n",
       "14                 -  \n",
       "15        JavaScript  \n",
       "16            Python  \n",
       "17              Java  \n",
       "18            Kotlin  \n",
       "19            Python  \n",
       "20              Java  \n",
       "21        TypeScript  \n",
       "22              Rust  \n",
       "23        TypeScript  \n",
       "24                Go  \n",
       "25               Vue  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4=pd.DataFrame({'Repository Title':Repository_t,'Repository Description':Repository_description,'Contributors Count':Contributors_count,'Language':Language})\n",
    "df4.index+=1\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2448f7",
   "metadata": {},
   "source": [
    "### 5. Scrape the details of top 100 songs on billiboard.com. \n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "22ce2b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\JPGD\\Documents\\ANDREA GOMEZ\\FLIP ROBO TECHNOLOGIES INTERNSHIP\\chromedriver_win32 2\\chromedriver.exe\")\n",
    "\n",
    "# Opening the page on automated chrome browser\n",
    "driver.get(\"https:/www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "903fc8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close popup window\n",
    "closew=driver.find_element(By.XPATH,\"/html/body/div[5]/div[2]/div/div/div[2]/div/div/button[1]\")\n",
    "closew.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "12e2ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click the menu button\n",
    "\n",
    "search_button=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[4]/div/div[1]/div[1]/button')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1be48b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click the chart option\n",
    "\n",
    "search_button=driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div/div/div/ul/li[1]/h3/button/span')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "623296a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click the Hot 100 option\n",
    "\n",
    "search_button=driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div/div/div/ul/li[1]/ul/li[2]/a')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "025b9081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists\n",
    "\n",
    "S_name=[]\n",
    "A_name=[]\n",
    "Lw_rank=[]\n",
    "P_rank=[]\n",
    "W_board=[]\n",
    "\n",
    "# Scraping search details\n",
    "\n",
    "sname_tag=driver.find_elements(By.XPATH,\"/html/body/div[4]/main/div[2]/div/div/div/div/div[2]/div/ul/li[4]/ul/li[1]/h3\")\n",
    "aname_tag=driver.find_elements(By.XPATH,\"/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div/ul/li[4]/ul/li[1]/span\")\n",
    "lw_rank_tag=driver.find_elements(By.XPATH,\"/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div/ul/li[4]/ul/li[4]/span\")\n",
    "p_rank_tag=driver.find_elements(By.XPATH,\"/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div/ul/li[4]/ul/li[5]/span\")\n",
    "W_board_tag=driver.find_elements(By.XPATH,\"/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div/ul/li[4]/ul/li[6]/span\")\n",
    "\n",
    "for i in sname_tag:\n",
    "    S_name.append(i.text)\n",
    "for i in aname_tag:\n",
    "    A_name.append(i.text)\n",
    "for i in lw_rank_tag:\n",
    "    Lw_rank.append(i.text)\n",
    "for i in p_rank_tag:\n",
    "    P_rank.append(i.text)\n",
    "for i in W_board_tag:\n",
    "    W_board.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a51da5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(S_name),len(A_name),len(Lw_rank),len(P_rank),len(W_board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ddddd3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Artist name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Calm Down</td>\n",
       "      <td>Rema &amp; Selena Gomez</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>All My Life</td>\n",
       "      <td>Lil Durk Featuring J. Cole</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Angel, Pt. 1</td>\n",
       "      <td>Kodak Black, NLE Choppa, Jimin, JVKE &amp; Muni Long</td>\n",
       "      <td>-</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Girl In Mine</td>\n",
       "      <td>Parmalee</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Moonlight</td>\n",
       "      <td>Kali Uchis</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Classy 101</td>\n",
       "      <td>Feid x Young Miko</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Bluffin</td>\n",
       "      <td>Gucci Mane &amp; Lil Baby</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Song name                                       Artist name  \\\n",
       "1      Last Night                                     Morgan Wallen   \n",
       "2        Fast Car                                        Luke Combs   \n",
       "3       Calm Down                               Rema & Selena Gomez   \n",
       "4         Flowers                                       Miley Cyrus   \n",
       "5     All My Life                        Lil Durk Featuring J. Cole   \n",
       "..            ...                                               ...   \n",
       "96   Angel, Pt. 1  Kodak Black, NLE Choppa, Jimin, JVKE & Muni Long   \n",
       "97   Girl In Mine                                          Parmalee   \n",
       "98      Moonlight                                        Kali Uchis   \n",
       "99     Classy 101                                 Feid x Young Miko   \n",
       "100       Bluffin                             Gucci Mane & Lil Baby   \n",
       "\n",
       "    Last week rank Peak rank Weeks on board  \n",
       "1                1         1             21  \n",
       "2                3         2             13  \n",
       "3                4         3             42  \n",
       "4                2         1             23  \n",
       "5                5         2              6  \n",
       "..             ...       ...            ...  \n",
       "96               -        65              2  \n",
       "97               -        97              1  \n",
       "98              90        80             11  \n",
       "99               -        99              1  \n",
       "100              -       100              1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5=pd.DataFrame({'Song name':S_name,'Artist name':A_name,'Last week rank':Lw_rank,'Peak rank':P_rank,'Weeks on board':W_board})\n",
    "df5.index+=1\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a0e7fa",
   "metadata": {},
   "source": [
    "### 6. Scrape the details of Highest sellingnovels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e95bc957",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\JPGD\\Documents\\ANDREA GOMEZ\\FLIP ROBO TECHNOLOGIES INTERNSHIP\\chromedriver_win32 2\\chromedriver.exe\")\n",
    "\n",
    "# Opening the page on automated chrome browser\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60d6f996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists\n",
    "B_name=[]\n",
    "A_name=[]\n",
    "V_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "\n",
    "# Scraping data\n",
    "B_name_tag=driver.find_elements(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[2]')\n",
    "A_name_tag=driver.find_elements(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[3]')\n",
    "V_sold_tag=driver.find_elements(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[4]')\n",
    "Publisher_tag=driver.find_elements(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[5]')\n",
    "Genre_tag=driver.find_elements(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[6]')\n",
    "\n",
    "for i in B_name_tag:\n",
    "    B_name.append(i.text)\n",
    "for i in A_name_tag:\n",
    "    A_name.append(i.text)\n",
    "for i in V_sold_tag:\n",
    "    V_sold.append(i.text)\n",
    "for i in Publisher_tag:\n",
    "    Publisher.append(i.text)\n",
    "for i in Genre_tag:\n",
    "    Genre.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01081f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(B_name),len(A_name),len(V_sold),len(Publisher),len(Genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41895dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book name</th>\n",
       "      <th>Author name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Book name       Author name  \\\n",
       "1                                    Da Vinci Code,The        Brown, Dan   \n",
       "2                 Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "3             Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "4            Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "5                                 Fifty Shades of Grey      James, E. L.   \n",
       "..                                                 ...               ...   \n",
       "96                                           Ghost,The    Harris, Robert   \n",
       "97                      Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "98               Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "99   Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "100  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "    Volumes sold        Publisher                        Genre  \n",
       "1      5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "2      4,475,152       Bloomsbury           Children's Fiction  \n",
       "3      4,200,654       Bloomsbury           Children's Fiction  \n",
       "4      4,179,479       Bloomsbury           Children's Fiction  \n",
       "5      3,758,936     Random House              Romance & Sagas  \n",
       "..           ...              ...                          ...  \n",
       "96       807,311     Random House   General & Literary Fiction  \n",
       "97       794,201          Penguin        Food & Drink: General  \n",
       "98       792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "99       791,507            Orion           Biography: General  \n",
       "100      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6=pd.DataFrame({'Book name':B_name,'Author name':A_name,'Volumes sold':V_sold,'Publisher':Publisher,'Genre':Genre})\n",
    "df6.index+=1\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af096bf",
   "metadata": {},
   "source": [
    "### 7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63e22259",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\JPGD\\Documents\\ANDREA GOMEZ\\FLIP ROBO TECHNOLOGIES INTERNSHIP\\chromedriver_win32 2\\chromedriver.exe\")\n",
    "\n",
    "# Opening the page on automated chrome browser\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "045a5e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists\n",
    "Name=[]\n",
    "Y_span=[]\n",
    "M_Genre=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]\n",
    "\n",
    "# Scraping data\n",
    "\n",
    "Name_tag=driver.find_elements(By.XPATH,\"/html/body/div[2]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div/div[2]/h3/a\")\n",
    "Y_span_tag=driver.find_elements(By.XPATH,\"/html/body/div[2]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div/div[2]/h3/span[2]\")\n",
    "M_Genre_tag=driver.find_elements(By.XPATH,\"/html/body/div[2]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div/div[2]/p[1]/span[5]\")\n",
    "Run_time_tag=driver.find_elements(By.XPATH,\"/html/body/div[2]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div/div[2]/p[1]/span[3]\")\n",
    "Ratings_tag=driver.find_elements(By.XPATH,\"/html/body/div[2]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div/div[2]/div[1]/div[1]/span[2]\")\n",
    "Votes_tag=driver.find_elements(By.XPATH,\"/html/body/div[2]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div/div[2]/p[4]/span[2]\")\n",
    "\n",
    "for i in Name_tag:\n",
    "    Name.append(i.text)\n",
    "for i in Y_span_tag:\n",
    "    Y_span.append(i.text)\n",
    "for i in M_Genre_tag:\n",
    "    M_Genre.append(i.text)\n",
    "for i in Run_time_tag:\n",
    "    Run_time.append(i.text)\n",
    "for i in Ratings_tag:\n",
    "    Ratings.append(i.text)\n",
    "for i in Votes_tag:\n",
    "    Votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e25825f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(Y_span),len(M_Genre),len(Run_time),len(Ratings),len(Votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65a9cd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Juego de tronos</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9,2</td>\n",
       "      <td>2.173.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8,7</td>\n",
       "      <td>1.251.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8,1</td>\n",
       "      <td>1.032.594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Por trece razones</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7,5</td>\n",
       "      <td>303.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Los 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7,6</td>\n",
       "      <td>262.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7,4</td>\n",
       "      <td>51.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Una serie de catastróficas desdichas</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7,8</td>\n",
       "      <td>63.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Mentes criminales</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8,1</td>\n",
       "      <td>208.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Scream</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7,1</td>\n",
       "      <td>43.405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>La maldición de Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8,6</td>\n",
       "      <td>260.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Name    Year span  \\\n",
       "1                         Juego de tronos  (2011–2019)   \n",
       "2                         Stranger Things  (2016–2024)   \n",
       "3                        The Walking Dead  (2010–2022)   \n",
       "4                       Por trece razones  (2017–2020)   \n",
       "5                                 Los 100  (2014–2020)   \n",
       "..                                    ...          ...   \n",
       "96                                  Reign  (2013–2017)   \n",
       "97   Una serie de catastróficas desdichas  (2017–2019)   \n",
       "98                      Mentes criminales     (2005– )   \n",
       "99                                 Scream  (2015–2019)   \n",
       "100            La maldición de Hill House       (2018)   \n",
       "\n",
       "                        Genre Run time Ratings      Votes  \n",
       "1    Action, Adventure, Drama   57 min     9,2  2.173.922  \n",
       "2      Drama, Fantasy, Horror   51 min     8,7  1.251.752  \n",
       "3     Drama, Horror, Thriller   44 min     8,1  1.032.594  \n",
       "4    Drama, Mystery, Thriller   60 min     7,5    303.589  \n",
       "5      Drama, Mystery, Sci-Fi   43 min     7,6    262.758  \n",
       "..                        ...      ...     ...        ...  \n",
       "96                      Drama   42 min     7,4     51.965  \n",
       "97   Adventure, Comedy, Drama   50 min     7,8     63.999  \n",
       "98      Crime, Drama, Mystery   42 min     8,1    208.556  \n",
       "99       Comedy, Crime, Drama   45 min     7,1     43.405  \n",
       "100    Drama, Horror, Mystery  572 min     8,6    260.250  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8=pd.DataFrame({'Name':Name,'Year span':Y_span,'Genre':M_Genre,'Run time':Run_time,'Ratings':Ratings,'Votes':Votes})\n",
    "df8.index+=1\n",
    "df8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ed400d",
   "metadata": {},
   "source": [
    "### 8. Details of Datasetsfrom UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e2a5749",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\JPGD\\Documents\\ANDREA GOMEZ\\FLIP ROBO TECHNOLOGIES INTERNSHIP\\chromedriver_win32 2\\chromedriver.exe\")\n",
    "\n",
    "# Opening the page on automated chrome browser\n",
    "driver.get(\"https://archive.ics.uci.edu/\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2af21ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close popup window\n",
    "closew=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/div/div[2]/button\")\n",
    "closew.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57b38ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click the search button\n",
    "\n",
    "search_button=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cdbf946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click \"Expand All\" button\n",
    "\n",
    "try:\n",
    "    search_button=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[1]/div/label[2]')\n",
    "    search_button.click()\n",
    "except NoSuchElementException as e:\n",
    "    print(\"Exception raised : \",e)\n",
    "    search_button=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[1]/div/label[2]/div[2]/span[2]')\n",
    "    search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f801aa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists\n",
    "\n",
    "Dataset_name=[]\n",
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_instances=[]\n",
    "No_attributes=[]\n",
    "Year=[]\n",
    "\n",
    "# Scraping data\n",
    "\n",
    "Dataset_name_tag=driver.find_elements(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div/div[1]/div[2]/h2/a\")\n",
    "Data_type_tag=driver.find_elements(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div/div[1]/div[2]/div/div[2]/span\")\n",
    "Task_tag=driver.find_elements(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div/div[1]/div[2]/div/div[1]/span\")\n",
    "Attribute_type_tag=driver.find_elements(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[2]\")\n",
    "No_instances_tag=driver.find_elements(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div/div/div[2]/div/div[3]/span\")\n",
    "No_attributes_tag=driver.find_elements(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div/div/div[2]/div/div[4]\")\n",
    "Year_tag=driver.find_elements(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[3]\")\n",
    "\n",
    "start=0\n",
    "end=62\n",
    "\n",
    "for page in range(start,end):\n",
    "    for i in Dataset_name_tag:\n",
    "        Dataset_name.append(i.text)  \n",
    "    for i in Data_type_tag:\n",
    "        Data_type.append(i.text)\n",
    "    for i in Task_tag:\n",
    "        Task.append(i.text)\n",
    "    for i in Attribute_type_tag:\n",
    "        Attribute_type.append(i.text)\n",
    "    for i in No_instances_tag:\n",
    "        No_instances.append(i.text)\n",
    "    for i in No_attributes_tag:\n",
    "        No_attributes.append(i.text)\n",
    "    for i in Year_tag:\n",
    "        Year.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[2]/div[3]/div/button[2]\")\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f80f68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620 620 620 620 620 620 620\n"
     ]
    }
   ],
   "source": [
    "print(len(Dataset_name),len(Data_type),len(Task),len(Attribute_type),len(No_instances),len(No_attributes),len(Year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fffa725",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "for i in Year:\n",
    "    b=i.replace(\"N/A\",\"N/A/NA\")\n",
    "    a.append(b.split(\"/\"))\n",
    "#print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fceb8fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "year=[x[2] for x in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab29ec56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset name</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of instances</th>\n",
       "      <th>No of attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Attributes</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Attributes</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Attributes</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>17 Attributes</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td></td>\n",
       "      <td>20 Attributes</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>Opinosis Opinion &amp;frasl; Review</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>51 Instances</td>\n",
       "      <td></td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Sattriya_Dance_Single_Hand_Gestures Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1.45K Instances</td>\n",
       "      <td></td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Undocumented</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>N/A</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>PMU-UD</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>5.18K Instances</td>\n",
       "      <td>9 Attributes</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>chestnut â€“ LARVIC</td>\n",
       "      <td>null</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td></td>\n",
       "      <td>1.45K Instances</td>\n",
       "      <td>3 Attributes</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>620 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Dataset name     Data type  \\\n",
       "1                                           Iris  Multivariate   \n",
       "2                                  Heart Disease  Multivariate   \n",
       "3                                          Adult  Multivariate   \n",
       "4                               Dry Bean Dataset  Multivariate   \n",
       "5                                       Diabetes                 \n",
       "..                                           ...           ...   \n",
       "616              Opinosis Opinion &frasl; Review                 \n",
       "617  Sattriya_Dance_Single_Hand_Gestures Dataset  Multivariate   \n",
       "618                                 Undocumented                 \n",
       "619                                       PMU-UD    Univariate   \n",
       "620                          chestnut â€“ LARVIC          null   \n",
       "\n",
       "                           Task              Attribute type   No of instances  \\\n",
       "1                Classification                        Real     150 Instances   \n",
       "2                Classification  Categorical, Integer, Real     303 Instances   \n",
       "3                Classification        Categorical, Integer  48.84K Instances   \n",
       "4                Classification               Integer, Real  13.61K Instances   \n",
       "5                                      Categorical, Integer                     \n",
       "..                          ...                         ...               ...   \n",
       "616                                                              51 Instances   \n",
       "617              Classification                         N/A   1.45K Instances   \n",
       "618                                                     N/A                     \n",
       "619              Classification                               5.18K Instances   \n",
       "620  Classification, Clustering                               1.45K Instances   \n",
       "\n",
       "    No of attributes  Year  \n",
       "1       4 Attributes  1988  \n",
       "2      13 Attributes  1988  \n",
       "3      14 Attributes  1996  \n",
       "4      17 Attributes  2020  \n",
       "5      20 Attributes    NA  \n",
       "..               ...   ...  \n",
       "616                   2010  \n",
       "617                   2019  \n",
       "618                     NA  \n",
       "619     9 Attributes  2018  \n",
       "620     3 Attributes  2017  \n",
       "\n",
       "[620 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8=pd.DataFrame({'Dataset name':Dataset_name,'Data type':Data_type,'Task':Task,'Attribute type':Attribute_type,\n",
    "                  'No of instances':No_instances,'No of attributes':No_attributes,'Year':year})\n",
    "df8.index+=1\n",
    "df8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
